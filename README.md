# Lipreading

Lipreading is a type of human-computer interaction based on visual information. From the perspective of pronunciation principle, lip is only one of the vocal tract organs, and it is difficult to express the complete pronunciation process. It is very challenging to recognize speech contents solely through lip movements. 


<img src="https://github.com/zsml132/Ideal_environment/blob/main/model.png" width="480px">


# Dataset

ICSLR. The dataset contains 656 sentences, with the length ranging from 2 to 8 Chinese characters. It covers 732 Chinese characters and 496 ”pinyin” combinations. The videos were recorded from the front and included 11 women 280 and 16 men. All of the subjects spoke Mandarin without moving their heads, and the light is kept the same during the recording. The video storage format is MP4, the resolution is 960×540, the frame rate is 25fps, and the audio sampling frequency is 48kHz. A total of 17712 videos were obtained. 

Download ICSLR from: GoogleDrive/BaiduDrive(key: to be upload)

Decompress the downloaded datasets into '/data'.

to be continue...

# Requires.
to be continue...


# Running...
to be continue...

## Citation

If you use this work in your research, please cite it as follows:

```latex
@article{sun2023malip,
  title={MALip: modal amplification lipreading based on reconstructed audio features},
  author={Sun, Baosheng and Xie, Dongliang and Shi, Haoze},
  journal={Signal Processing: Image Communication},
  volume={117},
  pages={117002},
  year={2023},
  publisher={Elsevier}
}
@inproceedings{sun2022lipreading,
  title={A Lipreading Model Based on Fine-Grained Global Synergy of Lip Movement},
  author={Sun, Baosheng and Xie, Dongliang and Luo, Dawei and Yin, Xiaojie},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)},
  pages={848--854},
  year={2022},
  organization={IEEE}
}



